{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GilOAhoo8PP"
   },
   "source": [
    "# Detecting Spots of Color\n",
    "\n",
    "In this notebook, a PiCamera is required.\n",
    "\n",
    "The user sets a target color (*`target_color` is a tuple describing an RGB color*) and then the algorithm tries to identify the location in the image that's the closest in terms of color to the one the user has set as a target. If the detected color represents more than 7% (*this 7% is represented by `color_threshold` variable*) of the entire image, then a contour with a green border is drawn around it.\n",
    "\n",
    "This is a color detection system that can be subsequently turned into an object detection system.\n",
    "\n",
    "Expect this to work at 4-5 FPS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfD-s3U-o8PR"
   },
   "source": [
    "Now let's import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYI2w-uno8PS"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "import picamera\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "import io\n",
    "import IPython\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2028TgzDo8PV"
   },
   "source": [
    "Next up we define 2 functions:\n",
    "\n",
    "* `showarray` - Used for showing a continuous stream of jpeg images.\n",
    "* `resizeNPArray` - Used for resizing a numpy array to another width/height by first converting it to an image and then putting it back into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GREn6M3o8PW"
   },
   "outputs": [],
   "source": [
    "# Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    '''\n",
    "    Function to display an image within a Jupyter notebook.\n",
    "    '''\n",
    "    f = io.BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue(), width = 480, height = 360))\n",
    "\n",
    "def resizeNPArray(array, width, height):\n",
    "    '''\n",
    "    Function to resize a given numpy array to another width/height,\n",
    "    whilst preserving the relative information - used for images.\n",
    "    '''\n",
    "    img = Image.fromarray(array)\n",
    "    img = img.resize((width, height), Image.ANTIALIAS)\n",
    "    resized = np.asarray(img)\n",
    "    return resized\n",
    "    \n",
    "def detectFacesAndEyes(img_array):\n",
    "    '''\n",
    "    Function to detect eyes and faces using a Haar-Cascade classifier.\n",
    "    '''\n",
    "    gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(img_array,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img_array[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpPHl3Vdo8PZ"
   },
   "source": [
    "This `ImageProcessor` class can be subsequently used for processing streams on multiple cores at the same time. \n",
    "\n",
    "For the time being, it's only used to process the queue of images that gets filled in the main thread with PiCamera.\n",
    "\n",
    "Now, the question is, how does this algorithm work?\n",
    "\n",
    "Each image is downsized a lot (from 320x240 pixels to 80x60 pixels) and then a KMeans algorithm is ran through. The data that is fed to KMeans has 5 dimensions:\n",
    "* 3 dimensions for the RGB color.\n",
    "* 2 dimensions for the position of the pixel in the image.\n",
    "\n",
    "By using another 2 dimensions in KMeans algorithm, we avoid having the labels of a color center appear in multiple locations of the image that have no link between said zones. The advantage is that this way, labels for a given color center will tend to clusterize together. The farther a potential candidate is from the cluster (of color center), the less likely it will get selected to be in the pool of those labels.\n",
    "\n",
    "Take this example: say there are 2 spots of white color in an image. By using only 3 dimensions with KMeans, we'd get the same labels for both zones of color. But if we are to use the extra 2 dimensions, there can no longer be 2 zones - the tendency to only have a single cluster of labels of the same kind gets to be big and helps at detecting the dominant zone where the color is the strongest (and has the largest size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1T9N5u1o8PZ"
   },
   "outputs": [],
   "source": [
    "class ImageProcessor(threading.Thread):\n",
    "    '''\n",
    "    Thread-safe class to process a stream of jpeg sequences from a given queue.\n",
    "    '''\n",
    "    def __init__(self, thread_stopper, frames, lock, target_color, border_color):\n",
    "        '''\n",
    "        thread_stopper -> Is the event which stops the thread when set.\n",
    "        frames -> The queue from which jpeg images come (in numpy.array format).\n",
    "        lock -> Mutex for the queue.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.thread_stopper = thread_stopper\n",
    "        self.frames = frames\n",
    "        self.lock = lock\n",
    "        self.target_color = target_color\n",
    "        self.border_color = border_color\n",
    "        self.incoming = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "        self.processed = np.zeros((240, 320, 3), dtype = np.uint8)\n",
    "        \n",
    "        self.verticals = np.array(80 * [np.arange(0, 60)]).T\n",
    "        self.verticals = self.verticals[:,:,np.newaxis]\n",
    "        \n",
    "        self.horizontals = np.array(60 * [np.arange(0, 80)])\n",
    "        self.horizontals = self.horizontals[:,:,np.newaxis]\n",
    "        \n",
    "    def run(self):\n",
    "        '''\n",
    "        Main thread which runs indefinitely until <<thread_stopper>> event is set.\n",
    "        This function processes each incoming image from the queue iteratively and then displays it in this notebook.\n",
    "        '''\n",
    "        while not thread_stopper.is_set():\n",
    "            try:\n",
    "                self.lock.acquire()\n",
    "                self.incoming = self.frames.get_nowait()\n",
    "                self.position, self.processed = self.dowork(self.incoming)\n",
    "                self.frames.task_done()\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            finally:\n",
    "                self.lock.release()\n",
    "            showarray(self.processed)\n",
    "            IPython.display.clear_output(wait = True)\n",
    "            \n",
    "    def dowork(self, array):\n",
    "        '''\n",
    "        array -> Is a numpy array that holds the a RGB image.\n",
    "        Function to process an image and detect spots of a given targeted color.\n",
    "        '''\n",
    "        \n",
    "        # down-sizing the image and running KMeans on it\n",
    "        output = array.copy()\n",
    "        array = resizeNPArray(array, 80, 60)\n",
    "        image_and_positions = np.concatenate((array, self.verticals, self.horizontals), axis = 2)\n",
    "        reshaped = image_and_positions.reshape((60 * 80, 5))\n",
    "        kmeans = KMeans(n_clusters = 6,\n",
    "                       n_init = 1,\n",
    "                       max_iter = 300,\n",
    "                       precompute_distances = True).fit(reshaped)\n",
    "        rgb_centers = kmeans.cluster_centers_[:, 0:3]\n",
    "        \n",
    "        labels_rgb = np.empty((4800, 3))\n",
    "        for i in range(6):\n",
    "            labels_rgb[kmeans.labels_ == i] = rgb_centers[i]\n",
    "        labels_rgb = labels_rgb.reshape((60, 80, 3)).astype(np.uint8)\n",
    "        \n",
    "        # getting the closest KMeans center to the targeted color\n",
    "        diff = rgb_centers - self.target_color\n",
    "        closest = np.sqrt(np.power(diff, 2).sum(axis = 1))\n",
    "        closest_label = closest.argmin()\n",
    "        \n",
    "        # determining the distribution of the targeted pixels\n",
    "        # (the target pixels are identified with the label of the selected KMeans center)\n",
    "        labels = kmeans.labels_.reshape((60, 80))\n",
    "        labels = labels == closest_label\n",
    "        sum_labels_vertical = labels.sum(axis = 1)\n",
    "        sum_labels_horizontal = labels.sum(axis = 0)\n",
    "        \n",
    "        # 4800 = 60 * 80 pixels\n",
    "        if not sum_labels_vertical.sum() > color_threshold * 4800:\n",
    "            return (None, output)\n",
    "        \n",
    "        # find the countour of the spot of color\n",
    "        non_zero_elements = np.nonzero(sum_labels_vertical)\n",
    "        # multiply by 4 to get to the original size\n",
    "        min_vertical = np.min(non_zero_elements) * 4\n",
    "        max_vertical = np.max(non_zero_elements) * 4\n",
    "        non_zero_elements = np.nonzero(sum_labels_horizontal)\n",
    "        min_horizontal = np.min(non_zero_elements) * 4\n",
    "        max_horizontal = np.max(non_zero_elements) * 4\n",
    "        \n",
    "        # and then draw a rectangle around the detected spot of color\n",
    "        output[min_vertical:max_vertical+1,min_horizontal,:] = self.border_color\n",
    "        output[min_vertical:max_vertical+1,max_horizontal,:] = self.border_color\n",
    "        output[min_vertical,min_horizontal:max_horizontal+1,:] = self.border_color\n",
    "        output[max_vertical,min_horizontal:max_horizontal+1,:] = self.border_color\n",
    "        \n",
    "        center_position = (min_vertical + max_vertical) / 2\n",
    "                \n",
    "        return (center_position, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3UDDXxJo8Pb"
   },
   "source": [
    "This is where everything gets instantiated and started.\n",
    "1. `target_color` represents the color we want to detect in the image. It works best with white.\n",
    "1. `border_color` represents the color of the border that surrounds a spot of color when detected.\n",
    "1. `color_threshold` represents the threshold percentage of the occupied space (per total space of the entire image) of the detected color at which the color is taken into consideration.\n",
    "1. `time_to_run` represents how much time in seconds the program will run for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUlC6Gtho8Pc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread joined\n"
     ]
    }
   ],
   "source": [
    "frames = queue.Queue(maxsize = 10)\n",
    "thread_stopper = threading.Event()\n",
    "lock = threading.Lock()\n",
    "color_threshold = 0.07 # in percentage\n",
    "time_to_run = 30 # in seconds\n",
    "\n",
    "#face testing\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "start = time.time()\n",
    "imageThreadRed = ImageProcessor(thread_stopper, frames, lock, np.array([255,0,0]), np.array([255,0,0])) #find red with red border\n",
    "imageThreadGreen = ImageProcessor(thread_stopper, frames, lock, np.array([0,255,0]), np.array([0,255,0])) #find green with green border\n",
    "imageThreadBlue = ImageProcessor(thread_stopper, frames, lock, np.array([0,0,255]), np.array([0, 0, 255])) #find blue with blue border\n",
    "\n",
    "imageThreadRed.start()\n",
    "imageThreadGreen.start()\n",
    "imageThreadBlue.start()\n",
    "\n",
    "with picamera.PiCamera() as camera:\n",
    "    camera.resolution = (320, 240)\n",
    "    camera.framerate = 30\n",
    "    camera.vflip = True\n",
    "    while time.time() - start < time_to_run:\n",
    "        freshest_frame = np.empty((240, 320, 3), dtype = np.uint8)\n",
    "        camera.capture_sequence([freshest_frame], use_video_port = True, format = 'rgb')\n",
    "        detectFacesAndEyes(freshest_frame)\n",
    "        lock.acquire()\n",
    "        if frames.full():\n",
    "            frames.get()\n",
    "            frames.task_done()\n",
    "        else:\n",
    "            frames.put(freshest_frame)\n",
    "        lock.release()\n",
    "print(\"picamera session ended\")\n",
    "\n",
    "thread_stopper.set()\n",
    "print(\"triggered image processing thread\")\n",
    "\n",
    "imageThreadRed.join()\n",
    "print(\"Red thread joined\")\n",
    "imageThreadGreen.join()\n",
    "print(\"Green thread joined\")\n",
    "imageThreadBlue.join()\n",
    "print(\"Blue thread joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNWO1P7Go8Pf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Detecting Spots of Color.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}